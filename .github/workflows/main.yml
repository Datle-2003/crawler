name: Crawler

on:
  workflow_dispatch:
  push:
    branches:
      - main
  schedule:
    - cron: "0 0 */3 * *"

jobs:
  crawl:
    runs-on: ubuntu-latest

    steps:
      - name: Check out this repo
        uses: actions/checkout@v2
      - name: Download Chrome
        run: |
          curl https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb --output chrome.deb
      - name: Install Chrome
        run: |
          sudo dpkg -i chrome.deb || sudo apt-get install -yf
      - name: Download Chrome Driver
        run: |
          wget https://chromedriver.storage.googleapis.com/LATEST_RELEASE
          export LATEST=$(cat LATEST_RELEASE)
          wget https://chromedriver.storage.googleapis.com/$LATEST/chromedriver_linux64.zip
          unzip chromedriver_linux64.zip
      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.9'
      - name: Install all necessary packages
        run: |
          python -m pip install --upgrade pip
          pip install psycopg2 urllib3 python-dotenv selenium scrapy
      - name: setup-chromedriver
        uses: nanasess/setup-chromedriver@v2.0.0
        with:
          chromedriver-version: ${{ env.LATEST }}
          chromedriver-path: ./chromedriver
      - name: Run crawler
        run: python crawler/main.py
